WEB DEVELOPMENT CODECADEMY

-----LECCION 1----- 
WHY TEST?

AUTOMATED TESTING: Automated testing is the use of software to control the execution of tests and the comparison of 
actual behavior to expected behavior. All the testing you just did (and more) could be performed by a computer program.

Compared to manual testing, automated testing is
- Faster: it tests more of your product in less time.
- More reliable: it’s less prone to error than a human is .
- Maintainable: you can review, edit, and extend a collection of tests.

Rather than hire a testing team at the end of development, professional developers can run their automated tests after 
every change. The workflow might look like this:
1. Write code and corresponding tests
2. Enter a command into a terminal to run tests
3. If the app behaves as intended, all tests should pass. Development is complete.
4. If it does not behave as intended, at least one test should fail. Fix code and return to step 2.

TEST SUITES: You run a test suite with 
	npm test 

Test code is included with and structured similarly to implementation code. Often times changes to test 
code are associated with changes to implementation code and vice versa. Both are easier to maintain when they are 
stored in the same place.

For example, if implementation code is written in index.js then the corresponding test code may be written in index-
test.js.

TESTS AS DOCUMENTATION: Tests as documentation provide what many other forms cannot: both human-readable text to 
describe the application and machine-executable code to confirm the app works as described.

This code block from the Cake Bar app describes and tests the “name” functionality.
	it('accepts the customer name', () => {
	  const name = 'Hungry Person';
	 
	  browser.url('/');
	  browser.setValue('#name', name);
	  browser.click('#submit-order');
	  browser.url('/');
	 
	  assert.include(browser.getText('#deliver-to'), name);
	});

You can read the description in plain English terms: it accepts the customer name. You can run the test to confirm 
the functionality works as described.

REGRESSION: When adding a new feature to your product, it’s possible that something will break. If that break occurs 
within a feature developed earlier, it is called regression. When functionality previously developed and tested stops 
working, you may say the functionality regressed.



-----LECCION 2-----
WRITE GOOD TESTS WITH MOCHA

INSTALL MOCHA: Before writing any tests you’ll need to use Node.js and npm to set up a JavaScript project and install 
Mocha.

The following command creates a file package.json that can be used to manage packages for the project.
	$ npm init

After running this command you will be prompted to enter information about your project. With your project setup, you 
can install packages.
	$ npm install mocha -D

-D signifies that this package is a development dependency and will show up under the devDependecies section in 
package.json. This means that the package will only be included in development mode and will not be included in the 
production bundle.

After installing Mocha as a dependency we can run it this way:
The method is to add a script to package.json. In the scripts object in package.json, set the value of "test" to 
mocha. It should look like this:

	"scripts": {
	  "test": "mocha"
	}

Now you can call Mocha with the following command:
	$ npm test

Instead of manually running each test in the test directory, you can use this command to run the full test suite 
automatically.

'DESCRIBE' AND 'IT' BLOCKS: In Mocha we group tests using the describe function and define tests using the it 
function. These two functions can be used to make your test suite complete, maintainable, and expressive in the 
following ways:
- Structure your test suite: you can organize tests into nested groups that reflect the structure of your 
  implementation code.
- Provide informative messages: you can define your tests using human-readable strings.

If you are testing a Math object with the method .max, you could use the following test code.

	describe('Math', () => {
	  describe('.max', () => {
	    it('returns the argument with the highest value', () => {
	      // Your test goes here
	    });
	    it('returns -Infinity when no arguments are provided', () => {
	      // Your test goes here
	    });
	  });
	});

Both the describe and it functions accept two parameters: a descriptive string and a callback function. Though the 
functions are flexible, they are commonly used in the structure above: nest describe blocks to resemble the structure 
of your implementation code and write individual tests in it blocks. This makes your test suite isolated, 
maintainable, and expressive.

ASSERT: In programming, a test compares an expected outcome to an actual outcome. For example, we expect the outcome 
of the following code… 	const a = 1 + 2; 	…to be: a has a value of 3.

assert.ok() allows you to compare values and throw errors as needed using one function call. The small, human-
readable format of the functions will help you make a more expressive test suite.

As a Node module, assert can be imported at the top of your files with
	const assert = require('assert');

You call assert functions like this:
	assert.ok(a === 3);

In this case a === 3 evaluates to true, so no error is thrown.

If an argument passed to assert.ok() evaluates to false, an AssertionError is thrown. The error communicates to Mocha 
that a test has failed, and Mocha logs the error message to the console.

SETUP, EXERCISE, AND VERIFY: This distinct and well-defined separation of steps makes your test more reliable, 
maintainable, and expressive.

The phases are defined as follows:
- Setup - create objects, variables, and set conditions that your test depends on
- Exercise - execute the functionality you are testing
- Verify - check your expectations against the result of the exercise phase. You can use the assert library here

TEARDOWN: Running multiple tests can introduce issues if the tests make changes to the testing environment: changes 
to the environment in one test might affect the next test. Some common changes to an environment include:
- altering files and directory structure
- changing read and write permissions on a file
- editing records in a database

To address this issue, we often add a teardown step to the end of our tests. The teardown phase makes our tests 
isolated by resetting the environment before the next test runs. This provides two key benefits:
- Changes to the environment caused by one test do not affect the other tests.
- Isolated tests can be executed in any order!

HOOKS: The Mocha test framework provides functions that enable us to reduce repetition, simplify the scope of each 
test, and more finely control the execution of our tests.

These functions (also referred to as hooks) are:
- beforeEach(callback) - callback is run before each test
- afterEach(callback) - callback is run after each test
- before(callback) - callback is run before the first test
- after(callback) - callback is run after the last test

Each hook accepts a callback to be executed at various times during a test. The before... hooks naturally happen 
before tests and are useful for separating out the setup steps of your tests. Meanwhile, the after... hooks are 
executed after tests and are useful for separating out the teardown steps of your tests.

	describe('messing around with hooks', () => {
	  let testValue; // Variable used by both tests
	 
	  beforeEach(() => {
	    testValue = 5;
	  });
	 
	  it('should add', () => {
	    // testValue = 5 <-- moved to beforeEach()
	    testValue = testValue + 5;
	    assert.equal(testValue, 10);
	  });
	 
	  it('should multiply', () => {
	    // testValue = 5 <-- moved to beforeEach()
	    testValue = testValue * 5;
	    assert.equal(testValue, 25);
	  });
	});

In this example, while each it() block could have set the testValue to 5, using the beforeEach() hook allows us to 
avoid that repetition while keeping each test isolated.



-----LECCION 3-----
WRITE EXPRESSIVE TESTS

ASSERT.EQUAL: You can use assert.ok() for most verifications, but sometimes it can be difficult to determine the 
condition you are evaluating.

Read the example code below. Will this assertion throw an error?

	const landAnimals = ['giraffe', 'squirrel'];
	const waterAnimals = ['shark', 'stingray'];
 
	landAnimals.push('frog');
	waterAnimals.push('frog');
 
	assert.ok(landAnimals[2] == waterAnimals[2]);

The above assertion is checking for equality. In order to understand this you must evaluate the entire expression 
within the parentheses of .ok(). You can instead use assert.equal() which does the == comparison for us.

In the example below, the two methods achieve the same outcome.
	assert.ok(landAnimals[2] == waterAnimals[2]);
	assert.equal(landAnimals[2], waterAnimals[2]);

The second line is more expressive: instead of parsing the entire statement, a reader only needs to read the first 
two words to know the test is verifying equality!

ASSERT.STRICTEQUAL: Take a look at the code below. Will these assertions throw errors?
	const a = 3;
	const b = '3';
	assert.ok(a == b);
	assert.ok(a === b);

- The first assertion will not throw an error because it uses loose (==) equality. It performs a type conversion when 
  comparing two things.
- The second will throw an error because it uses strict (===) equality. It returns false if the types differ.

If you need to be strict in evaluating equality, you can use assert.strictEqual().
- assert.equal() performs a == comparison
- assert.strictEqual() performs a === comparison

Compare the following code to the first example. This code performs the same verifications, but it is more 
expressive. Without parsing any logic, a reader would know the intention of your tests by reading the method names.

	const a = 3;
	const b = '3';
	assert.equal(a, b);
	assert.strictEqual(a, b);

The assert documentation recommends always using assert.strictEqual() instead of assert.equal().

ASSERT.DEEPEQUAL: Do you think these assertions will throw errors?
	const a = {relation: 'twin', age: '17'};
	const b = {relation: 'twin', age: '17'};
	assert.equal(a, b);
	assert.strictEqual(a, b);

Both assertions will throw an error because distinct objects are not considered equal when using either loose or 
strict equality in JavaScript.

If you need to compare the values within two objects, you can use assert.deepEqual(). This method compares the values 
of each object using loose (==) equality.

The following code will not throw an error:
	assert.deepEqual(a, b);

ASSERT.DEEPEQUAL ON ARRAYS: Arrays are also objects, so deepEqual() also compares their values with loose equality.
	const arr1 = [1, 2, 3];
	const arr2 = [1, 2, 3];
	const arr3 = [1, 2, '3'];
 
	assert.deepEqual(arr1, arr2); // No error
	assert.deepEqual(arr1, arr3); // No error

ALL THE ASSERT METHODS AVAILABLE: https://nodejs.org/api/assert.html



-----LECCION 4-----
THE TESTING PYRAMID

UNIT TESTS: Unit tests are isolated and fast tests that check one small behavior within your web application.
For example, we want to test whether our database can save a comment. Saving does not involve the view or server. 
We can create a test that writes directly to the database, and the test itself doesn’t need to know about the other 
layers.

A test like this is fast, but only gives you confidence that a small slice of your system is working as intended.

SYSTEM TESTS: System tests are a group of fully integrated tests that exercise your entire web application.
For example, we want to test whether our blog renders with the correct post and comments. We can write a test that 
checks whether a browser renders a stored blog post. This test exercises every layer of the web application:

- The database stores the blog post.
- The server sends the HTML to the browser.
- The browser renders the view.

A test like this is slow and less descriptive but provides you with confidence that a large slice of your system is 
working as intended. 

INTEGRATION TESTS: Integration tests include everything between unit tests and system tests. They exercise multiple 
parts of the web application, often in different layers.

For example, an integration test may check whether your web application can save a server-generated comment to the 
database. This test integrates two layers of your web application:

- The server receives the comment and sends it to the database.
- The database stores your comment.

Developers often call tests like the one above end-to-end tests, because they start in the browser (one end) and 
traverse the stack to the database (other end).

Integration tests are faster than system tests, but slower than unit tests. They provide less confidence (that your 
feature works as expected) than system tests and more confidence than unit tests.

SHAPE OF A TESTING SUITE: The goal of a full-stack web application’s testing suite is to provide you with confidence 
that your application works as expected while executing in a timely fashion.

You could write few integration tests that provide you with confidence, and more unit tests that execute quickly and 
provide you with specific feedback. The number and types of unit and integration tests that you write can be mapped 
onto the testing pyramid.

THE TESTING PYRAMID: The testing pyramid is an approach to structuring your test suite.

- Browser-level integration tests sit on the top of the pyramid. This layer is the narrowest because it should have  
  the fewest number of tests — the slow nature of browser-level tests make them more expensive than server-level 
  tests.

- While server tests don’t need to interact with the browser, they usually exercise parts of the model or database. 
  They sit close to the middle of the spectrum between unit and system tests. They provide a moderate level of 
  confidence as they may exercise multiple layers of the stack. Server tests are more expensive and provide less 
  specific error messages than model tests.

- Compared to browser and server tests, model and database tests exercise a smaller portion of the stack. They 
  provide the most specific feedback, but not much confidence that the whole system is working as expected. Because 
  they are the cheapest, you can write a lot of them without significantly slowing the amount of time it takes to run 
  your test suite.



-----LECCION 5-----
OUTSIDE-IN TEST-DRIVEN DEVELOPMENT

RED, GREEN, REFACTOR: Test-driven development (TDD) is the process of writing tests before implementation code. You 
use the feedback from your tests to inform the implementation of a feature or outcome.

A common approach to TDD is the red, green, refactor cycle. When you write a test before the implementation exists 
you start “in the red” phase, because your test fails and outputs a red error message. Next, you write the minimum 
implementation code to get your test to pass. This puts you “in the green” phase, because your test passes and 
outputs a green message.

Once you are in the green, you should consider whether your implementation is the best or most efficient approach. If 
you think your code could be written more efficiently or cleaner, then you enter the refactor phase. You can refactor 
your code with confidence, because you have tests that cover the expected behavior.

OUTSIDE-INT TDD: Outside-in TDD is an approach that developers use to build full-stack web applications. It leverages 
the same red, green, refactor steps that we covered above, but with one caveat — a failing test does not always 
inform you to write new implementation code. Instead, it may require that you implement new functionality at a 
different level.

You start at the top of the stack, the view, and write tests as you work your way towards the database layer.

If a test pushes you to a lower level, you restart your red, green, refactor cycle by writing a new test. This test 
informs the implementation at your new layer. You continue the TDD cycle at this lower level until:
- You need to drop another layer to implement the desired behavior
- You have addressed the reason for dropping to the current layer

Once you address the reason for dropping a layer, you can start working your way back up the testing pyramid. If 
you’re in the model/database layer, you step up to the server, and run your server tests to see if you get a 
different response. The response should be one of the following:
- The test passes — you can start another red, green, refactor cycle at the server level or step up to the view layer.
- The test fails — the server test that pushed you to the model layer fails, but for a different reason. This is 
  common, and indicates that you’re making progress. This failure may indicate that you need to write additional 
  implementation at the server level, or drop back to the model.



-----LECCION 6-----
OUTSIDE-IN EXAMPLE: 
You have a movie blog and want to develop a feature that renders user comments under your blog posts. The application 
should render no more than ten comments when a user lands on the web page. The application should present the 
comments in reverse chronological order (i.e. the most recent comment should be first).

Let’s assume the web application generates HTML at the server — any updates to the view require implementation at the 
server level.

FEATURE TESTING: The first step is to write a feature test that checks if your web application is rendering comments 
to the browser. Let’s use the following outside-in TDD approach:

1. Write a test that checks for the presence of a comment under a blog post.
2. The test fails, because your web application does not render comments.
3. Because your web application generates HTML at the server layer, you drop to the server to address the error.

Although we could continue to write feature tests to check for the number of rendered comments, we know server tests 
are cheaper, so we can test those details when we drop a layer.

SERVER TESTING: At the server layer, we start by writing a test that informs the implementation of our server-
generated HTML. Because our web application renders unique comments from the database, we want to check that the 
server-generated HTML is dynamic.

1. Write a test that checks for the presence of a dynamically generated comment element in the server HTML.
2. The test fails, so we add implementation for a server-generated comment.
3. Once we’re in the green and consider refactoring, we want to write a test that calls a method at the model layer, 
   let’s call it Comment.latest(). At the server layer, we’ll check if the method returns comments from the database.
3. Because this method doesn’t exist, we must drop to the model/database layer.

MODEL AND DATABASE TESTING: At the model layer, we start by writing a test that informs the implementation of our 
Comment.latest method. This method requires that you interface with the web application’s database.

1. Write a test that checks if the Comment.latest method returns ten comments when the database has eleven comments.
2. Implement the Comment.latest method to return ten comments, so the test is green.
3. Once you’ve considered refactoring, write a test that checks whether the method returns the last ten comments in 
   reverse chronological order.
4. Implement and refactor
5. Write a test that checks if Comment.latest() returns an empty array when your database is empty.
6. Implement and refactor
7. Write a test that checks if Comment.latest returns the correct number and order of comments when your database has 
   between zero and ten comments in it.
8. Implement and refactor

TAKING STOCK: At this point, your entire test suite should be green. You have written seven new tests, and the 
implementation code to make them pass — your web application should render the last ten comments from your database 
in reverse chronological order.

Let’s take stock of our seven new tests:
1. Feature: Comments are rendered to a user’s browser.
2. Server: The server generates an HTML field for comments.
3. Server: The server has access to ten comments from the database.
4. Model: The Comment.latest method returns ten comments from your database.
5. Model: The Comment.latest method returns the last ten comments in your database in reverse chronological order.
6. Model: The Comment.latest method returns an empty array when your database has zero comments.
7. Model: The Comment.latest method returns all of the comments when your database has between zero and ten comments.

Once your feature is working as expected, you should consider how your new tests fit into the broader test suite. The 
rest of the test suite could have few tests, or over one hundred. It’s time to refactor.



-----LECCION 7-----
TDD FEATURE-LEVEL TESTS

- When developing a new feature and practicing outside-in development, feature tests are where we’ll typically start.
- Feature tests often incorporate every layer of the application and — using WebDriverI/O and Mocha — exercise 
  features in the same way that a human user would. They’re a good tool for reproducing end-user behavior.
- Feedback from feature tests is usually in terms of HTML (i.e. that text or button that you said would be on the page 
  isn’t on the page).
- Because feature tests typically hit every layer of a developer’s stack, they are slower than tests at lower layers, 
  and errors thrown in feature tests can be difficult to interpret and provide little guidance on what the developer 
  can do to resolve them.

CHAI: Node.js has a default assertion library that provides enough functionality to write basic test code. The Chai 
testing library extends the types of assertions we can make. Chai is an assertion library for Node.js and browsers 
that can be paired with any JavaScript testing framework.

PHANTOMJS: PhantomJS is a headless browser scriptable with a JavaScript API, which allows us to write tests that mimic 
user interaction and then evaluate the results. It does not require us to render the application in a browser.

A browser runs “headless” when it doesn’t render anything to the screen, but runs in the background.

WEBDRIVER I/O: WebdriverIO provides methods that allow us to programmatically interact with the user-facing elements 
of our app in the headless browser that PhantomJS runs.



-----LECCION 8-----
SERVER TESTING STACK

Server tests are used to test the server response only, not any front-end rendering of code or user interactions. We “disconnect” the browser and interact directly with the server using requests. Server tests are commonly used to test API responses.

THE SUPERTEST LIBRARY: We are using the function request to make server calls to support our tests. This is actually a 
reference to the SuperTest library:
	const request = require('supertest');

This library was specifically designed for testing Node server responses and integrates well with Mocha and Chai. To 
use SuperTest, we pass the app object from our app into the request function. To make a GET request, we use .get() 
with the desired route as the argument:
	await request(app)
	          .get('/')
	          .send();

It is also possible to perform a POST using SuperTest. We chain any desired properties or inputs to the HTTP call, and 
use .send() to make the request:
	await request(app)
	          .post('/messages')
	          .type('form')
	          .send({author, message}); 



-----LECCION 9-----
SERVER TESTING PATTERNS

One question to ask when deciding between a full feature test versus a server test is:
	“Is it worth trading a slow feature test for a faster server test that doesn’t test the UI?”

STATUS CODES: Server tests are slightly faster than browser-driven feature tests. Since the web browser is cut out of 
the test, we are not testing how things are rendered for the user.

One use of TDD at the server level is to ensure that the HTTP status codes are returned as expected.
To verify status codes, we are asserting that the response status is equal to the status code integer that our 
application requires:
	assert.equal(response.status, 200);

RESPONSE CONTENT: We need to make sure the server is responding with the correct content. 
We can organize our tests into two categories:
	- tests that exercise the “Happy Path” — expected use cases of our application
	- tests that exercise the “Sad Path” — unexpected or invalid use of our application
	
For our tests, once we retrieve the response from the server, we use assert.include() from the Chai library to check 
the response.

EJ: 	response.text = '<div><div id="my-name">My Name</div></div>';
	assert.include(parseTextFromHTML(response.text, '#my-name'), "My Name"); 	//True
	
